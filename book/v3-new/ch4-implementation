第四章代码规划。

既然都写了，那肯定就是尽可能多探索一些可能性啊。

需要实现内核动态内存分配。
需要实现用户和内核地址空间隔离。这样做完之后即使内核在低地址空间（比如依然是 0x80020000）上也不会产生冲突，用户程序就直接从 0x0 开始即可。那么内核是在低地址还是高地址呢？和之前兼容还是弄到 0xffffffff80020000 上去吧。
隔离会使得实现和之前有一些不同之处：
1. __alltraps 和 __restore 属于内核的数据段，只有将 satp 切换到内核空间才能访问。虽然修改 stvec 之后，用户能够以 S 特权级跳转到 __alltraps，但是这条指令是没法访问的，因为 satp 还是用户的地址空间。所以 xv6 里面的做法是：将 __alltraps 和 __restore 放在一个 page 里面映射到用户和内核地址空间。这个 page 原先放在内核的数据段里面，在创建地址空间的时候，分配一个物理页框，将这个 page 里面的内容拷贝进去，并映射到虚拟地址空间的最高 page。于是只需将 stvec 设置为这个地址，无论是用户还是内核进入 Trap，都可以访问。

用户在 trampoline 的时候如何知道内核的 satp ，又怎么知道专属的内核栈的位置：可以直接把内核栈的位置放在 sscratch 中，satp 放到 TrapContext 中就好了。需要注意的是，需要将 satp 切换到内核之后才能把寄存器保存到内核栈上的 TrapContext。直接在用户地址空间里面放一个内核的 satp 就好了，并将这个段设置为不允许用户访问。如此的话，在用户 Trap 跳转到 __alltraps 的时候是可以访问的。这样，从特权级来说没有什么安全隐患，但是不知道从处理器层面有没有幽灵/熔断等漏洞。具体还需要看一下 xv6 中的设计。

内核 satp 能在哪里找到？（参考 xv6 设计）

用户/内核栈的动态/静态分配？

2. 在内核修改用户地址空间没有那么容易，需要手动查用户页表来获得物理地址。如果要读写大量数据只能逐页。但是这并不构成什么问题。

3. 地址空间分布和以往不同。内核地址空间存放进程的内核栈（以及可能的内核线程的栈），还有 trampoline page，以及线性映射的整块物理内存（包括内核代码、数据段和其他部分），此外，还有恒等映射的设备 MMIO。用户地址空间存放用户代码、数据段，堆空间和最高的 trampoline page 还有次高的用户栈。

一些值得讨论的问题：
1. 之后希望支持内核线程来做一些（多核）同步互斥的内容。目前设计的话，内核线程和用户进程可以共存，分别命名 KernelThread 和 Process。它们的 ControlBlock 都需要包含 MemorySet。它们都能够作为调度单位，因此需要一个特别的 Trait 能够丢到调度队列中。如果这样的话，Trap 就存在下面这些可能：
[1] 用户进程从 U 进入 S Trap（中断/异常）
[2] 用户进程从 S 进入 S Trap (目前仅有的一种可能是在处理 syscall 的时候又打开了 S 中断)
[3] 内核线程从 S 进入 S Trap (目前只能是通过中断，也有可能是异常)，内核线程不会使用 syscall 而是直接调用内核接口
因此 Trap 相关处理能否涵盖这些情况需要特别注意。
其中只有 [1] 需要换栈和换 satp，[2][3] 都不需要换栈和 satp，因为本身就已经在内核态了。那么这两种情况能否共用一套 __alltraps 和 __restore？目前还不清楚。xv6 里面是[1] 发生之后跳转到特别处理 U 的 handler，在里面修改 stvec 到一套新的 __alltraps 和 __restore。所以依然可以考虑从 sstatus.spp 判断是否需要换栈，这也是老传世经典了。

MemorySet 的设计是一个相对独立也比较简单的内容。基本上直接沿用原 v3 的设计即可。只不过，在映射空间的类型上需要更加考虑到后面的拓展，如 COW/mmap/sbrk 等等延迟映射
